{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc82e847-111f-41c3-98b8-1bccf577a6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, os\n",
    "torch.manual_seed(0) \n",
    "import warnings;warnings.filterwarnings(\"ignore\")\n",
    "from HINT.dataloader import csv_three_feature_2_dataloader, generate_admet_dataloader_lst\n",
    "from HINT.molecule_encode import MPNN, ADMET\n",
    "from HINT.icdcode_encode import GRAM, build_icdcode2ancestor_dict\n",
    "from HINT.protocol_encode import Protocol_Embedding\n",
    "from HINT.model import HINTModel \n",
    "device = torch.device(\"cpu\")  ## cuda:0\n",
    "if not os.path.exists(\"figure\"):\n",
    "    os.makedirs(\"figure\")\n",
    "    \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostClassifier\n",
    "import lightgbm as lgb\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score, precision_recall_curve, precision_score, recall_score, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cfd564e1-88ec-476c-bcd3-25dd3ec13026",
   "metadata": {},
   "outputs": [],
   "source": [
    "mpnn_model = MPNN(mpnn_hidden_size = 50, mpnn_depth=3, device = device)\n",
    "icdcode2ancestor_dict = build_icdcode2ancestor_dict()\n",
    "gram_model = GRAM(embedding_dim = 50, icdcode2ancestor = icdcode2ancestor_dict, device = device)\n",
    "protocol_model = Protocol_Embedding(output_dim = 50, highway_num=3, device = device)\n",
    "\n",
    "molecule_encoder = mpnn_model\n",
    "disease_encoder = gram_model\n",
    "protocol_encoder = protocol_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "20fbd19a-eaf3-4e92-86e8-21c1dcb56dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embed(dataloader):\n",
    "    nctid_lst, label_lst, smiles_lst2, icdcode_lst3, criteria_lst = [], [], [], [], []\n",
    "    for nctid, label, smiles, icdcode, criteria in dataloader:\n",
    "        nctid_lst.extend(nctid)\n",
    "        label_lst.extend([i.item() for i in label])\n",
    "        smiles_lst2.extend(smiles)\n",
    "        icdcode_lst3.extend(icdcode)\n",
    "        criteria_lst.extend(criteria)\n",
    "        \n",
    "    molecule_embed = molecule_encoder.forward_smiles_lst_lst(smiles_lst2)\n",
    "    icd_embed = disease_encoder.forward_code_lst3(icdcode_lst3)\n",
    "    protocol_embed = protocol_encoder.forward(criteria_lst)\n",
    "    print(molecule_embed.shape, icd_embed.shape, protocol_embed.shape)\n",
    "    return molecule_embed, icd_embed, protocol_embed\n",
    "\n",
    "def preprocess(file, loader):\n",
    "    df = pd.read_csv(file)\n",
    "    df.drop(['phase', 'why_stop'], axis=1, inplace=True)\n",
    "    df.drop(['icdcodes', 'smiless', 'criteria'], axis=1, inplace=True)\n",
    "    df.drop(['diseases', 'drugs'], axis=1, inplace=True) ## FE later\n",
    "    \n",
    "    molecule_embed, icd_embed, protocol_embed = get_embed(loader)\n",
    "\n",
    "    molecule_df = pd.DataFrame(molecule_embed.detach().numpy(), columns=[f'molecule_feature_{i}' for i in range(len(molecule_embed[0]))])\n",
    "    icd_df = pd.DataFrame(icd_embed.detach().numpy(), columns=[f'icd_feature_{i}' for i in range(len(icd_embed[0]))])\n",
    "    protocol_df = pd.DataFrame(protocol_embed.detach().numpy(), columns=[f'protocol_feature_{i}' for i in range(len(protocol_embed[0]))])\n",
    "\n",
    "    df = pd.concat([df, molecule_df, icd_df, protocol_df], axis=1)\n",
    "    return df\n",
    "\n",
    "def print_metrics(y_true, y_pred, label):\n",
    "    print(f\"{label} ROC AUC: {round(roc_auc_score(y_true, y_pred),3)}\")\n",
    "    print(f\"{label} F1: {round(f1_score(y_true, y_pred),3)}\")\n",
    "    precision, recall, _ = precision_recall_curve(y_true, y_pred)\n",
    "    print(f\"{label} PR-AUC: {round(auc(recall, precision),3)}\")\n",
    "    print(f\"{label} Precision: {round(precision_score(y_true, y_pred),3)}\")\n",
    "    print(f\"{label} Recall: {round(recall_score(y_true, y_pred),3)}\")\n",
    "    print(f\"{label} Accuracy: {round(accuracy_score(y_true, y_pred),3)}\")\n",
    "    print(f\"{label} Predict 1 ratio: {round(sum(y_pred) / len(y_pred),3)}\")\n",
    "    print(f\"{label} Label 1 ratio: {round(sum(y_true) / len(y_true),3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "471f1562-a184-4b4e-a343-4a71465b20a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomEnsemble:\n",
    "    def __init__(self, xgb_params, cat_params, lgbm_params):\n",
    "        self.xgb_model = xgb.XGBClassifier(**xgb_params)\n",
    "        self.cat_model = CatBoostClassifier(**cat_params)\n",
    "        self.lgbm_model = lgb.LGBMClassifier(**lgbm_params, verbosity=-1)\n",
    "        \n",
    "    def fit(self, train_df, valid_df, test_df):\n",
    "        # pre-process for xgb\n",
    "        train_idx = range(len(train_df))\n",
    "        valid_idx = range(len(train_df), len(train_df) + len(valid_df))\n",
    "        test_idx = range(len(train_df) + len(valid_df), len(train_df) + len(valid_df) + len(test_df))\n",
    "        combined_df = pd.DataFrame()\n",
    "        combined_df = pd.concat([train_df, valid_df, test_df], axis=0)\n",
    "        combined_df.reset_index(drop=True, inplace=True)\n",
    "        combined_df = pd.get_dummies(combined_df, columns=['status'], drop_first=True)\n",
    "        train_xgb = combined_df.loc[train_idx]\n",
    "        valid_xgb = combined_df.loc[valid_idx]\n",
    "        test_xgb = combined_df.loc[test_idx]\n",
    "        X_train_xgb, y_train = train_xgb.drop(['nctid','label'], axis=1), train_xgb['label']  \n",
    "        X_valid_xgb, y_valid = valid_xgb.drop(['nctid','label'], axis=1), valid_xgb['label']  \n",
    "        X_test_xgb, y_test = test_xgb.drop(['nctid','label'], axis=1), test_xgb['label']  \n",
    "        self.test_xgb = X_test_xgb\n",
    "        \n",
    "        self.xgb_model.fit(X_train_xgb, y_train)\n",
    "\n",
    "        # pre-process for catboost, lgbm\n",
    "        X_train_cl, y_train = train_df.drop(['nctid','label'], axis=1), train_df['label']  \n",
    "        X_valid_cl, y_valid = valid_df.drop(['nctid','label'], axis=1), valid_df['label']  \n",
    "        X_test_cl, y_test = test_df.drop(['nctid','label'], axis=1), test_df['label']\n",
    "        X_train_cl['status'] = train_df['status'].astype('category')\n",
    "        X_valid_cl['status'] = valid_df['status'].astype('category')\n",
    "        X_test_cl['status'] = test_df['status'].astype('category')\n",
    "        self.test_cl = X_test_cl\n",
    "        self.y_true = y_test\n",
    "        \n",
    "        self.cat_model.fit(X_train_cl, y_train, cat_features=[0], verbose=0)\n",
    "        self.lgbm_model.fit(X_train_cl, y_train)\n",
    "        \n",
    "    def predict(self):\n",
    "        xgb_prob = self.xgb_model.predict_proba(self.test_xgb)[:, 1]\n",
    "        cat_prob = self.cat_model.predict_proba(self.test_cl)[:, 1]\n",
    "        lgbm_prob = self.lgbm_model.predict_proba(self.test_cl)[:, 1]\n",
    "        final_prob = (xgb_prob + cat_prob + lgbm_prob) / 3\n",
    "        threshold = 0.5\n",
    "        final_pred = (final_prob >= threshold).astype(int)\n",
    "        return final_pred\n",
    "        \n",
    "    def evaluate(self):\n",
    "        y_true = self.y_true\n",
    "        y_pred = self.predict()\n",
    "        print_metrics(y_true, y_pred, 'Test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "317260c8-71ab-4f0c-ae32-5aef01dfbf72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_evaluate(phase):\n",
    "    params_dict = {\n",
    "        'phase_I': {\n",
    "            'xgb': {'alpha': 10, 'learning_rate': 0.15, 'max_depth': 3, 'n_estimators': 100},\n",
    "            'cat': {'iterations': 200, 'depth': 3, 'l2_leaf_reg': 1},\n",
    "            'lgbm': {'learning_rate': 0.05, 'max_depth': 3, 'n_estimators': 100, 'num_leaves': 31},\n",
    "        },\n",
    "        'phase_II': {\n",
    "            'xgb': {'alpha': 5, 'learning_rate': 0.05, 'max_depth': 3, 'n_estimators': 100},\n",
    "            'cat': {'iterations': 100, 'depth': 6, 'l2_leaf_reg': 5},\n",
    "            'lgbm': {'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 100, 'num_leaves': 31},\n",
    "        },\n",
    "        'phase_III': {\n",
    "            'xgb': {'alpha': 5, 'learning_rate': 0.05, 'max_depth': 3, 'n_estimators': 100},\n",
    "            'cat': {'iterations': 200, 'depth': 5, 'l2_leaf_reg': 1},\n",
    "            'lgbm': {'learning_rate': 0.05, 'max_depth': 6, 'n_estimators': 100, 'num_leaves': 31},\n",
    "        },\n",
    "    }\n",
    "    base_name = phase\n",
    "    datafolder = \"data\" \n",
    "    train_file = os.path.join(datafolder, base_name + '_train.csv')\n",
    "    valid_file = os.path.join(datafolder, base_name + '_valid.csv')\n",
    "    test_file = os.path.join(datafolder, base_name + '_test.csv')\n",
    "    \n",
    "    train_loader = csv_three_feature_2_dataloader(train_file, shuffle=True, batch_size=32) \n",
    "    valid_loader = csv_three_feature_2_dataloader(valid_file, shuffle=False, batch_size=32) \n",
    "    test_loader = csv_three_feature_2_dataloader(test_file, shuffle=False, batch_size=32) \n",
    "\n",
    "    train_df = preprocess(train_file, train_loader)\n",
    "    valid_df = preprocess(valid_file, valid_loader)\n",
    "    test_df = preprocess(test_file, test_loader)\n",
    "    print(train_df.shape, valid_df.shape, test_df.shape)\n",
    "\n",
    "    phase_params = params_dict[phase]\n",
    "    ensemble_model = CustomEnsemble(phase_params['xgb'], phase_params['cat'], phase_params['lgbm'])\n",
    "    ensemble_model.fit(train_df, valid_df, test_df)\n",
    "    ensemble_model.evaluate()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4027075c-b9a9-440a-b548-979fcac1eabe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1044, 50]) torch.Size([1044, 50]) torch.Size([1044, 50])\n",
      "torch.Size([117, 50]) torch.Size([117, 50]) torch.Size([117, 50])\n",
      "torch.Size([627, 50]) torch.Size([627, 50]) torch.Size([627, 50])\n",
      "(1044, 153) (117, 153) (627, 153)\n",
      "Test ROC AUC: 0.864\n",
      "Test F1: 0.894\n",
      "Test PR-AUC: 0.91\n",
      "Test Precision: 0.838\n",
      "Test Recall: 0.957\n",
      "Test Accuracy: 0.874\n",
      "Test Predict 1 ratio: 0.632\n",
      "Test Label 1 ratio: 0.553\n"
     ]
    }
   ],
   "source": [
    "ensemble_evaluate('phase_I')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7c9167ed-b75a-442b-a7bb-a5cf81770cd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4005, 50]) torch.Size([4005, 50]) torch.Size([4005, 50])\n",
      "torch.Size([446, 50]) torch.Size([446, 50]) torch.Size([446, 50])\n",
      "torch.Size([1654, 50]) torch.Size([1654, 50]) torch.Size([1654, 50])\n",
      "(4005, 153) (446, 153) (1654, 153)\n",
      "Test ROC AUC: 0.783\n",
      "Test F1: 0.845\n",
      "Test PR-AUC: 0.868\n",
      "Test Precision: 0.751\n",
      "Test Recall: 0.965\n",
      "Test Accuracy: 0.803\n",
      "Test Predict 1 ratio: 0.713\n",
      "Test Label 1 ratio: 0.555\n"
     ]
    }
   ],
   "source": [
    "ensemble_evaluate('phase_II')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "087b8cd3-d4de-4874-b695-e2aba58dcdd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3094, 50]) torch.Size([3094, 50]) torch.Size([3094, 50])\n",
      "torch.Size([344, 50]) torch.Size([344, 50]) torch.Size([344, 50])\n",
      "torch.Size([1146, 50]) torch.Size([1146, 50]) torch.Size([1146, 50])\n",
      "(3094, 153) (344, 153) (1146, 153)\n",
      "Test ROC AUC: 0.714\n",
      "Test F1: 0.875\n",
      "Test PR-AUC: 0.913\n",
      "Test Precision: 0.851\n",
      "Test Recall: 0.901\n",
      "Test Accuracy: 0.807\n",
      "Test Predict 1 ratio: 0.794\n",
      "Test Label 1 ratio: 0.75\n"
     ]
    }
   ],
   "source": [
    "ensemble_evaluate('phase_III')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
